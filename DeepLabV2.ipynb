{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/annanasnas/semantic_segmentation-25/blob/main/DeepLabV2.ipynb)"
      ],
      "metadata": {
        "id": "p-cEQRdrCgv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "ON08hQzIyGx8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPO = \"https://github.com/annanasnas/semantic_segmentation-25.git\"\n",
        "!git clone $REPO\n",
        "%cd /content/semantic_segmentation-25\n",
        "!pip install -q -r requirements.txt pyyaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDdLtFA6yrE9",
        "outputId": "5ec3afac-4e45-441b-acd8-10134acf242c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'semantic_segmentation-25'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 144 (delta 58), reused 114 (delta 32), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (144/144), 302.30 KiB | 12.09 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "/content/semantic_segmentation-25\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "usM7DI7Ny4Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open(\"configs/deeplabv2.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "!python scripts/download_data.py\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = cfg[\"train\"][\"batch_size\"]\n",
        "epochs = cfg[\"train\"][\"epochs\"]\n",
        "data_dir = cfg[\"data\"][\"root\"]\n",
        "learning_rate = cfg[\"train\"][\"lr\"]\n",
        "img_size = cfg[\"data\"][\"img_size\"]\n",
        "name = cfg[\"model\"][\"name\"]"
      ],
      "metadata": {
        "id": "Eg08IBbau_S3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoaders"
      ],
      "metadata": {
        "id": "A-DW3ceDyygA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets.cityscapes import CityScapes\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "])\n",
        "\n",
        "train_dataset = CityScapes(\n",
        "    root_dir=data_dir,\n",
        "    split=\"train\",\n",
        "    image_transform=image_transforms,\n",
        "    image_size=img_size\n",
        ")\n",
        "\n",
        "val_dataset = CityScapes(\n",
        "    root_dir=data_dir,\n",
        "    split=\"val\",\n",
        "    image_transform=image_transforms,\n",
        "    image_size=img_size\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "HG4PBKBLtG6S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "G_0-Q0bZy1Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "qICzC2Ovoz80",
        "outputId": "36468b37-403d-4472-bd82-d29c8c4a48dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from models.deeplabv2.deeplabv2 import get_deeplab_v2\n",
        "from scripts.train import train_model\n",
        "from torch.amp import autocast, GradScaler\n",
        "from scripts.checkpoint import Checkpoint\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "model = get_deeplab_v2()\n",
        "optimizer = optim.SGD(model.optim_parameters(lr=learning_rate), momentum=0.9, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=255)\n",
        "scheduler = optim.lr_scheduler.PolynomialLR(optimizer, total_iters=50, power=0.9)\n",
        "scaler = GradScaler()\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "ckpt_dir = Path(\"/content/drive/MyDrive/semantic segmentation/checkpoints\") / name\n",
        "log_csv  = ckpt_dir / \"log.csv\"\n",
        "ckpt_mgr = Checkpoint(ckpt_dir)\n",
        "ckpt = Checkpoint(ckpt_dir)\n",
        "\n",
        "best_path = ckpt_dir / \"best.pth\"\n",
        "if best_path.exists():\n",
        "    ckpt = torch.load(best_path, map_location=\"cpu\", weights_only=False)\n",
        "    model.load_state_dict(ckpt[\"model\"])\n",
        "    optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
        "    scaler.load_state_dict(ckpt[\"scaler\"])\n",
        "    scheduler.load_state_dict(ckpt[\"scheduler\"])\n",
        "    start_epoch = ckpt[\"epoch\"]\n",
        "    best_miou   = ckpt[\"best_miou\"]\n",
        "    df_prev = pd.read_csv(log_csv)\n",
        "    metrics = df_prev.to_dict(\"list\")\n",
        "else:\n",
        "    start_epoch = 0\n",
        "    best_miou   = 0\n",
        "    metrics = {\"epoch\": [], \"train_loss\": [], \"val_loss\": [], \"val_miou\": []}\n",
        "\n",
        "train_model(model, train_dataloader, val_dataloader,\n",
        "            device, epochs, autocast, scaler,\n",
        "            optimizer, criterion, scheduler,\n",
        "            ckpt_mgr, start_epoch, best_miou,\n",
        "            log_csv, metrics)"
      ],
      "metadata": {
        "id": "meEY2Vcjvq1V",
        "outputId": "e5c69040-c022-4836-c8a0-ce9f7602608f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deeplab pretraining loading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/_compile.py:32: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
            "  return disable_fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-325699075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbest_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scaler\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "90kG_qFLe3Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scripts.utils import create_final_table, evaluate_miou\n",
        "import warnings, logging\n",
        "\n",
        "logging.getLogger(\"fvcore.nn.jit_analysis\").setLevel(logging.ERROR)\n",
        "\n",
        "model = get_deeplab_v2()\n",
        "best_model = torch.load(best_path, map_location=device)\n",
        "best_model.load_state_dict(best_model[\"model\"])\n",
        "\n",
        "df = create_final_table(model, name, device, (img_size, img_size*2), epochs)\n",
        "df[\"mIoU (%)\"] = evaluate_miou(best_model, val_dataloader, device) * 100\n",
        "print(df.to_markdown(index=False))"
      ],
      "metadata": {
        "id": "XqyEmv0V2QKY",
        "outputId": "7d925083-2f6c-4100-ef43-a06263a6b1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Model                 | Latency                                                                | FLOPs   | Params   |   mIoU (%) |\n",
            "|:----------------------|:-----------------------------------------------------------------------|:--------|:---------|-----------:|\n",
            "| deeplabv2 - 50 epochs | Mean latency: 0.25 +/- 0.01, Mean FPS: 4.14 +/- 2.51 frames per second | 376.1 G | 43.9 M   |    52.0803 |\n"
          ]
        }
      ]
    }
  ]
}